{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Track Assignment: Char RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book chosen: Lord Of The Rings first book (LOTR 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from learning import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938278"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('lotr1.txt', 'r').read().lower()\n",
    "# remove some unwanted characters\n",
    "text = text.replace('\\xa0', ' ')\n",
    "text = text.replace('/', '') \n",
    "text = text.replace('*', '')\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 57\n"
     ]
    }
   ],
   "source": [
    "char_to_idx = {char: idx for (idx, char) in enumerate(list(set(text)))}\n",
    "idx_to_char = {idx: char for (char, idx) in char_to_idx.items()}\n",
    "one_hot_size = len(char_to_idx)\n",
    "print(f'Number of unique characters: {one_hot_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = OneHotDataset(60, 3, text, char_to_idx, one_hot_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "hidden_size = 256\n",
    "batch_size = 512\n",
    "lr = 0.001\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 2.372396403755962\n",
      "Epoch 1, loss: 1.8951143701415991\n",
      "Epoch 2, loss: 1.689835849643339\n",
      "Epoch 3, loss: 1.5628491493762027\n",
      "Epoch 4, loss: 1.4750569395464883\n",
      "Epoch 5, loss: 1.4100031522994345\n",
      "Epoch 6, loss: 1.3586820596173625\n",
      "Epoch 7, loss: 1.3162987154166164\n",
      "Epoch 8, loss: 1.2797546778880242\n",
      "Epoch 9, loss: 1.2471281524180586\n",
      "Epoch 10, loss: 1.2172560764022426\n",
      "Epoch 11, loss: 1.1893460916419272\n",
      "Epoch 12, loss: 1.162863648367006\n",
      "Epoch 13, loss: 1.1373860793105903\n",
      "Epoch 14, loss: 1.11264721168824\n",
      "Epoch 15, loss: 1.0898446897242933\n",
      "Epoch 16, loss: 1.0664823427918304\n",
      "Epoch 17, loss: 1.0460560579346752\n",
      "Epoch 18, loss: 1.0290625857253317\n",
      "Epoch 19, loss: 1.0189671581778705\n",
      "Epoch 20, loss: 1.0160599636758407\n",
      "Epoch 21, loss: 1.0106739944209835\n",
      "Epoch 22, loss: 1.0058257832464728\n",
      "Epoch 23, loss: 0.996593036940367\n",
      "Epoch 24, loss: 0.9873158620539352\n",
      "Epoch 25, loss: 0.9805808860424498\n",
      "Epoch 26, loss: 0.9730567108784877\n",
      "Epoch 27, loss: 0.9671263012870439\n",
      "Epoch 28, loss: 0.9561812377210139\n",
      "Epoch 29, loss: 0.9513177322482906\n"
     ]
    }
   ],
   "source": [
    "char_rnn = CharRNN(hidden_size=hidden_size, vocab_size=len(char_to_idx), input_size=one_hot_size).to(device)\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "optim = torch.optim.Adam(char_rnn.parameters(), lr=lr)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    run_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        optim.zero_grad()\n",
    "        out, h = char_rnn(x.transpose(0, 1), None)\n",
    "        l = loss(out, y)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "\n",
    "        run_loss += l.item()\n",
    "    if verbose:\n",
    "        print(f'Epoch {epoch}, loss: {run_loss/len(loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment to avoid overwriting the model\n",
    "torch.save(char_rnn.state_dict(), 'char_rnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_rnn = CharRNN(hidden_size=hidden_size, vocab_size=len(char_to_idx), input_size=one_hot_size).to(device)\n",
    "char_rnn.load_state_dict(torch.load('char_rnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output shape (batch_size, vocab_size)\n",
    "# input shape (seq_len, batch_size, input_size)\n",
    "\n",
    "def char_to_onehot(char, char_to_idx):\n",
    "    x = torch.zeros(1, 1, one_hot_size).to(device)\n",
    "    x[0, 0, char_to_idx[char]] = 1\n",
    "    \n",
    "    return x\n",
    "\n",
    "def seq_to_onehot(seq, char_to_idx):\n",
    "    x = torch.zeros(len(seq), 1, one_hot_size)\n",
    "    for t, char in enumerate(seq):\n",
    "        x[t, 0, char_to_idx[char]] = 1\n",
    "\n",
    "    return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, length, start, char_to_idx, idx_to_char): # generate text from nothing\n",
    "    with torch.no_grad():\n",
    "        for temperature in [0.2, 0.5, 1.2]:\n",
    "            generated = start # start from space\n",
    "            input = seq_to_onehot(generated, char_to_idx)\n",
    "            out, h = model(input, None)\n",
    "            p = F.softmax(out / temperature, dim=1)\n",
    "            idx = torch.distributions.Categorical(p[0]).sample().item()\n",
    "            generated += idx_to_char[idx]\n",
    "            last_char = generated[-1]\n",
    "\n",
    "            for _ in range(length):\n",
    "                out, h = model(char_to_onehot(last_char, char_to_idx), h) \n",
    "                out = torch.divide(out, temperature)\n",
    "                p = F.softmax(out, dim=1)\n",
    "                idx = torch.distributions.Categorical(p[0]).sample().item()\n",
    "                generated += idx_to_char[idx]\n",
    "                last_char = generated[-1]\n",
    "                \n",
    "            print(f'Temperature: {temperature}\\n{generated}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frodo realized that a dark presence was following him \n",
      "Temperature: 0.2\n",
      "frodo realized that a dark presence was following him a great beatir and both. the eastern shore and many land benowing on the eastern sky. there was a black shat speechess of letten brought them from the bound towers or stood as it seemed to be a still here the shadow of long years and delly. and if we cannot stain the world to see the ring of mordor. \n",
      "\n",
      "Temperature: 0.5\n",
      "frodo realized that a dark presence was following him at last.  for he began to have set imily. it was hattered with him. the air were the dark with with a side north and hands, and some of the eastern followile the sare or heard of a white for a moment he gates and stirm. he spoke the mist or fally great smooth and the councing for it. then he came to \n",
      "\n",
      "Temperature: 1.2\n",
      "frodo realized that a dark presence was following him leaks age now feel south:. but in this i compantor may brea, forward, holes! seeing they caught i have tons. he can,\" eanty queetleb!\" in the easter hig out of us. but me appeared to be ansuen and bolomir, and quirrig. here alieady norther, now were await; \"now to in only or joy where for you movy or\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = 'frodo realized that a dark presence was following him '\n",
    "print(start)\n",
    "generate_text(char_rnn, 300, start, char_to_idx, idx_to_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
